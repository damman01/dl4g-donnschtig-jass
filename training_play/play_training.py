import os

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

import logging
import random

from pathlib import Path

import pandas as pd
import tensorflow as tf
import tensorflow.keras.mixed_precision as mixed_precision
from keras.callbacks import TensorBoard
from tensorflow import keras

from play_training_data_prep_json import get_train_data


# This function generates training data from a list of files
def data_generator(list_files: list, batch_size: int = 10000):
    while True:
        for file_name in list_files:
            with open(file_name, 'r') as file:
                print("\nReading file:", file_name)
                lines = file.readlines()
                random.shuffle(lines)
                for i in range(0, len(lines), batch_size):
                    batch_lines = lines[i:i+batch_size]
                    data = get_train_data(batch_lines)
                    x_train = pd.concat(data[0], ignore_index=True).values
                    y_categorical_data_train = keras.utils.to_categorical(data[1])
                    yield x_train, y_categorical_data_train


# This function trains the model using the data generated by the data_generator function
def train_model(learning_model, train_generator, val_generator, train_steps, val_steps):
    if tf.test.gpu_device_name():
        print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
    else:
        print("Please install GPU version of TF by running  'python3 -m pip install tensorflow[and-cuda]' in your WSL "
              "Environment!")
        raise Exception("Please install GPU version of TF by running  'python3 -m pip install tensorflow[and-cuda]'")

    # open TensorBoard with: 'tensorboard --logdir=logs' in separate terminal
    tb_callback = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)

    train_steps = max(1, train_steps)
    val_steps = max(1, val_steps)

    model_history = learning_model.fit(
        train_generator,
        steps_per_epoch=train_steps,
        epochs=10,
        callbacks=[tb_callback],
        validation_data=val_generator,
        validation_steps=val_steps
    )
    return model_history


if __name__ == "__main__":
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    script_dir = os.path.dirname(os.path.abspath(__file__))
    # paths_to_data = os.path.join(script_dir, "./gamelogs/")
    # paths_to_data = os.path.join(script_dir, "./gamelogs/jass_game_0001/")
    paths_to_data = os.path.join(script_dir, "./test_files/jass_game_0001/")

    # Set up mixed precision
    policy = mixed_precision.Policy('mixed_float16')
    mixed_precision.set_global_policy(policy)

    # Create a MirroredStrategy for distributed training
    if tf.config.list_physical_devices('GPU'):
        strategy = tf.distribute.MirroredStrategy()
    else:
        strategy = None

    # Model creation
    with strategy.scope():
        model = keras.Sequential([
            keras.layers.Input(shape=(82,)),
            keras.layers.Reshape((1, 82)),  # Reshape input data to add a time step dimension
            keras.layers.LSTM(128),  # Recurrent Layer (LSTM, GRU): These layers are used for
            # sequence data like time series or text where the order of inputs matters. the Attention layer expects
            # its input to be a sequence of vectors, not a single vector. The LSTM layer, by default, returns only
            # the last output in the output sequence. By setting return_sequences=True, it will return the full
            # sequence of outputs, which can then be used as input to the Attention layer.
            keras.layers.Dense(200, activation='relu'),
            keras.layers.Dense(400, activation='relu'),
            keras.layers.BatchNormalization(),  # BatchNormalization: These layers can help accelerate training.
            keras.layers.Dense(800, activation='relu'),
            keras.layers.Dense(1600, activation='relu'),
            keras.layers.Dense(3200, activation='relu'),
            keras.layers.LeakyReLU(),
            keras.layers.ELU(alpha=1.0),
            keras.layers.Dropout(rate=0.2),
            keras.layers.Dense(1600, activation='relu'),
            keras.layers.Dense(800, activation='relu'),
            keras.layers.Dense(400, activation='relu'),
            keras.layers.Dense(200, activation='relu'),
            keras.layers.Dense(100, activation='relu'),
            keras.layers.Dense(36, activation='softmax')
        ])
        if policy.name == 'mixed_float16':
            model.add(keras.layers.Dense(36, activation='softmax', dtype='float32'))

        optimizer = keras.optimizers.Adam(learning_rate=0.01)
        model.compile(loss='categorical_crossentropy',
                      optimizer=optimizer,
                      metrics=['accuracy'])

    print('Searching directory...:', paths_to_data)
    file_list = []

    for file in Path(paths_to_data).rglob('*.txt'):
        file_list.append(file)
    file_list.sort()
    print('Found {} files.'.format(len(file_list)))

    train_files = file_list[:int(len(file_list) * 0.7)]
    val_files = file_list[int(len(file_list) * 0.8):]
    test_files = file_list[int(len(file_list) * 0.9):]
    print("Train files:", len(train_files))
    print("Val files:", len(val_files))
    print("Test files:", len(test_files))

    # Create the generators
    train_gen = data_generator(train_files)

    val_gen = data_generator(val_files)

    # Train the model
    history = train_model(model, train_gen, val_gen, len(train_files), len(val_files))
    logger.info("Trained model with history:")
    logger.info(history)

    # Save the model
    model.save('../models/playModelTest.keras')

    val_gen = data_generator(val_files)
    # Evaluate the model on the validation set
    score = model.evaluate(val_gen, steps=len(val_files))
    logger.info("Evaluation on validation set:")
    logger.info(score)

    # Test the model on new data
    test_gen = data_generator(test_files)

    test_loss, test_acc = model.evaluate(test_gen, steps=len(test_files))
    logger.info("Testing on new data:")
    logger.info("Test loss:", test_loss)
    logger.info("Test accuracy:", test_acc)
